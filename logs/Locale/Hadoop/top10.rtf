{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf0 \CocoaLigature0 MacBook-Pro-di-davinder:~ davinderkumar$ hadoop jar Documents/workspace/BigDataHW1_Hadoop/target/HadoopHW1-0.0.1-SNAPSHOT.jar HadoopTop10ProductsForUser.Top10ProductsForUserMain 2011_2012.csv output\
17/05/18 01:11:09 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
17/05/18 01:11:10 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\
17/05/18 01:11:10 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\
17/05/18 01:11:10 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\
17/05/18 01:11:10 INFO input.FileInputFormat: Total input files to process : 1\
17/05/18 01:11:10 INFO mapreduce.JobSubmitter: number of splits:2\
17/05/18 01:11:10 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2071942224_0001\
17/05/18 01:11:11 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\
17/05/18 01:11:11 INFO mapreduce.Job: Running job: job_local2071942224_0001\
17/05/18 01:11:11 INFO mapred.LocalJobRunner: OutputCommitter set in config null\
17/05/18 01:11:11 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:11:11 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:11:11 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\
17/05/18 01:11:11 INFO mapred.LocalJobRunner: Waiting for map tasks\
17/05/18 01:11:11 INFO mapred.LocalJobRunner: Starting task: attempt_local2071942224_0001_m_000000_0\
17/05/18 01:11:11 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:11:11 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:11:11 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
17/05/18 01:11:11 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
17/05/18 01:11:11 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/davinderkumar/2011_2012.csv:0+134217728\
17/05/18 01:11:11 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
17/05/18 01:11:11 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
17/05/18 01:11:11 INFO mapred.MapTask: soft limit at 83886080\
17/05/18 01:11:11 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
17/05/18 01:11:11 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
17/05/18 01:11:11 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
17/05/18 01:11:12 INFO mapreduce.Job: Job job_local2071942224_0001 running in uber mode : false\
17/05/18 01:11:12 INFO mapreduce.Job:  map 0% reduce 0%\
17/05/18 01:11:12 INFO mapred.LocalJobRunner: \
17/05/18 01:11:12 INFO mapred.MapTask: Starting flush of map output\
17/05/18 01:11:12 INFO mapred.MapTask: Spilling map output\
17/05/18 01:11:12 INFO mapred.MapTask: bufstart = 0; bufend = 7448101; bufvoid = 104857600\
17/05/18 01:11:12 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25212780(100851120); length = 1001617/6553600\
17/05/18 01:11:13 INFO mapred.MapTask: Finished spill 0\
17/05/18 01:11:13 INFO mapred.Task: Task:attempt_local2071942224_0001_m_000000_0 is done. And is in the process of committing\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: map\
17/05/18 01:11:13 INFO mapred.Task: Task 'attempt_local2071942224_0001_m_000000_0' done.\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local2071942224_0001_m_000000_0\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: Starting task: attempt_local2071942224_0001_m_000001_0\
17/05/18 01:11:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:11:13 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:11:13 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
17/05/18 01:11:13 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
17/05/18 01:11:13 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/davinderkumar/2011_2012.csv:134217728+58725112\
17/05/18 01:11:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
17/05/18 01:11:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
17/05/18 01:11:13 INFO mapred.MapTask: soft limit at 83886080\
17/05/18 01:11:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
17/05/18 01:11:13 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
17/05/18 01:11:13 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
17/05/18 01:11:13 INFO mapreduce.Job:  map 100% reduce 0%\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: \
17/05/18 01:11:13 INFO mapred.MapTask: Starting flush of map output\
17/05/18 01:11:13 INFO mapred.MapTask: Spilling map output\
17/05/18 01:11:13 INFO mapred.MapTask: bufstart = 0; bufend = 3318057; bufvoid = 104857600\
17/05/18 01:11:13 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25768188(103072752); length = 446209/6553600\
17/05/18 01:11:13 INFO mapred.MapTask: Finished spill 0\
17/05/18 01:11:13 INFO mapred.Task: Task:attempt_local2071942224_0001_m_000001_0 is done. And is in the process of committing\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: map\
17/05/18 01:11:13 INFO mapred.Task: Task 'attempt_local2071942224_0001_m_000001_0' done.\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local2071942224_0001_m_000001_0\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: map task executor complete.\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: Waiting for reduce tasks\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: Starting task: attempt_local2071942224_0001_r_000000_0\
17/05/18 01:11:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:11:13 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:11:13 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
17/05/18 01:11:13 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
17/05/18 01:11:13 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@630fc733\
17/05/18 01:11:13 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10\
17/05/18 01:11:13 INFO reduce.EventFetcher: attempt_local2071942224_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\
17/05/18 01:11:13 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2071942224_0001_m_000000_0 decomp: 7948913 len: 7948917 to MEMORY\
17/05/18 01:11:13 INFO reduce.InMemoryMapOutput: Read 7948913 bytes from map-output for attempt_local2071942224_0001_m_000000_0\
17/05/18 01:11:13 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7948913, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7948913\
17/05/18 01:11:13 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2071942224_0001_m_000001_0 decomp: 3541165 len: 3541169 to MEMORY\
17/05/18 01:11:13 INFO reduce.InMemoryMapOutput: Read 3541165 bytes from map-output for attempt_local2071942224_0001_m_000001_0\
17/05/18 01:11:13 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 3541165, inMemoryMapOutputs.size() -> 2, commitMemory -> 7948913, usedMemory ->11490078\
17/05/18 01:11:13 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\
17/05/18 01:11:13 INFO mapred.LocalJobRunner: 2 / 2 copied.\
17/05/18 01:11:13 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\
17/05/18 01:11:13 INFO mapred.Merger: Merging 2 sorted segments\
17/05/18 01:11:13 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 11490014 bytes\
17/05/18 01:11:14 INFO reduce.MergeManagerImpl: Merged 2 segments, 11490078 bytes to disk to satisfy reduce memory limit\
17/05/18 01:11:14 INFO reduce.MergeManagerImpl: Merging 1 files, 11490080 bytes from disk\
17/05/18 01:11:14 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\
17/05/18 01:11:14 INFO mapred.Merger: Merging 1 sorted segments\
17/05/18 01:11:14 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 11490044 bytes\
17/05/18 01:11:14 INFO mapred.LocalJobRunner: 2 / 2 copied.\
17/05/18 01:11:14 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\
17/05/18 01:11:15 INFO mapred.Task: Task:attempt_local2071942224_0001_r_000000_0 is done. And is in the process of committing\
17/05/18 01:11:15 INFO mapred.LocalJobRunner: 2 / 2 copied.\
17/05/18 01:11:15 INFO mapred.Task: Task attempt_local2071942224_0001_r_000000_0 is allowed to commit now\
17/05/18 01:11:15 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2071942224_0001_r_000000_0' to hdfs://localhost:9000/user/davinderkumar/output/_temporary/0/task_local2071942224_0001_r_000000\
17/05/18 01:11:15 INFO mapred.LocalJobRunner: reduce > reduce\
17/05/18 01:11:15 INFO mapred.Task: Task 'attempt_local2071942224_0001_r_000000_0' done.\
17/05/18 01:11:15 INFO mapred.LocalJobRunner: Finishing task: attempt_local2071942224_0001_r_000000_0\
17/05/18 01:11:15 INFO mapred.LocalJobRunner: reduce task executor complete.\
17/05/18 01:11:16 INFO mapreduce.Job:  map 100% reduce 100%\
17/05/18 01:11:16 INFO mapreduce.Job: Job job_local2071942224_0001 completed successfully\
17/05/18 01:11:16 INFO mapreduce.Job: Counters: 35\
	File System Counters\
		FILE: Number of bytes read=23034750\
		FILE: Number of bytes written=43457929\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=520115696\
		HDFS: Number of bytes written=10676503\
		HDFS: Number of read operations=22\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=5\
	Map-Reduce Framework\
		Map input records=361958\
		Map output records=361958\
		Map output bytes=10766158\
		Map output materialized bytes=11490086\
		Input split bytes=238\
		Combine input records=0\
		Combine output records=0\
		Reduce input groups=358938\
		Reduce shuffle bytes=11490086\
		Reduce input records=361958\
		Reduce output records=358938\
		Spilled Records=723916\
		Shuffled Maps =2\
		Failed Shuffles=0\
		Merged Map outputs=2\
		GC time elapsed (ms)=614\
		Total committed heap usage (bytes)=1174929408\
	Shuffle Errors\
		BAD_ID=0\
		CONNECTION=0\
		IO_ERROR=0\
		WRONG_LENGTH=0\
		WRONG_MAP=0\
		WRONG_REDUCE=0\
	File Input Format Counters \
		Bytes Read=192946936\
	File Output Format Counters \
		Bytes Written=10676503\
\
\
Tempo impiegato HadoopTop10: 7.345}