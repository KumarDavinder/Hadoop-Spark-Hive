{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf820
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf0 \CocoaLigature0 MacBook-Pro-di-davinder:~ davinderkumar$ hadoop jar Documents/workspace/BigDataHW1_Hadoop/target/HadoopHW1-0.0.1-SNAPSHOT.jar HadoopTop5ProductsForMonth.Top5ProductsMain 2011_2012.csv out\
17/05/18 01:13:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\
17/05/18 01:13:12 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\
17/05/18 01:13:12 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\
17/05/18 01:13:13 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\
17/05/18 01:13:13 INFO input.FileInputFormat: Total input files to process : 1\
17/05/18 01:13:13 INFO mapreduce.JobSubmitter: number of splits:2\
17/05/18 01:13:13 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1466891302_0001\
17/05/18 01:13:13 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\
17/05/18 01:13:13 INFO mapreduce.Job: Running job: job_local1466891302_0001\
17/05/18 01:13:13 INFO mapred.LocalJobRunner: OutputCommitter set in config null\
17/05/18 01:13:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:13:13 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:13:13 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\
17/05/18 01:13:13 INFO mapred.LocalJobRunner: Waiting for map tasks\
17/05/18 01:13:13 INFO mapred.LocalJobRunner: Starting task: attempt_local1466891302_0001_m_000000_0\
17/05/18 01:13:13 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:13:13 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:13:13 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
17/05/18 01:13:13 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
17/05/18 01:13:13 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/davinderkumar/2011_2012.csv:0+134217728\
17/05/18 01:13:13 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
17/05/18 01:13:13 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
17/05/18 01:13:13 INFO mapred.MapTask: soft limit at 83886080\
17/05/18 01:13:13 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
17/05/18 01:13:13 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
17/05/18 01:13:13 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
17/05/18 01:13:14 INFO mapreduce.Job: Job job_local1466891302_0001 running in uber mode : false\
17/05/18 01:13:14 INFO mapreduce.Job:  map 0% reduce 0%\
17/05/18 01:13:15 INFO mapred.LocalJobRunner: \
17/05/18 01:13:15 INFO mapred.MapTask: Starting flush of map output\
17/05/18 01:13:15 INFO mapred.MapTask: Spilling map output\
17/05/18 01:13:15 INFO mapred.MapTask: bufstart = 0; bufend = 5508910; bufvoid = 104857600\
17/05/18 01:13:15 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25212780(100851120); length = 1001617/6553600\
17/05/18 01:13:15 INFO mapred.MapTask: Finished spill 0\
17/05/18 01:13:15 INFO mapred.Task: Task:attempt_local1466891302_0001_m_000000_0 is done. And is in the process of committing\
17/05/18 01:13:15 INFO mapred.LocalJobRunner: map\
17/05/18 01:13:15 INFO mapred.Task: Task 'attempt_local1466891302_0001_m_000000_0' done.\
17/05/18 01:13:15 INFO mapred.LocalJobRunner: Finishing task: attempt_local1466891302_0001_m_000000_0\
17/05/18 01:13:15 INFO mapred.LocalJobRunner: Starting task: attempt_local1466891302_0001_m_000001_0\
17/05/18 01:13:15 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:13:15 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:13:15 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
17/05/18 01:13:15 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
17/05/18 01:13:15 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/davinderkumar/2011_2012.csv:134217728+58725112\
17/05/18 01:13:15 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\
17/05/18 01:13:15 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\
17/05/18 01:13:15 INFO mapred.MapTask: soft limit at 83886080\
17/05/18 01:13:15 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\
17/05/18 01:13:15 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\
17/05/18 01:13:15 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\
17/05/18 01:13:15 INFO mapreduce.Job:  map 100% reduce 0%\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: \
17/05/18 01:13:16 INFO mapred.MapTask: Starting flush of map output\
17/05/18 01:13:16 INFO mapred.MapTask: Spilling map output\
17/05/18 01:13:16 INFO mapred.MapTask: bufstart = 0; bufend = 2454166; bufvoid = 104857600\
17/05/18 01:13:16 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 25768188(103072752); length = 446209/6553600\
17/05/18 01:13:16 INFO mapred.MapTask: Finished spill 0\
17/05/18 01:13:16 INFO mapred.Task: Task:attempt_local1466891302_0001_m_000001_0 is done. And is in the process of committing\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: map\
17/05/18 01:13:16 INFO mapred.Task: Task 'attempt_local1466891302_0001_m_000001_0' done.\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: Finishing task: attempt_local1466891302_0001_m_000001_0\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: map task executor complete.\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: Waiting for reduce tasks\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: Starting task: attempt_local1466891302_0001_r_000000_0\
17/05/18 01:13:16 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\
17/05/18 01:13:16 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\
17/05/18 01:13:16 INFO util.ProcfsBasedProcessTree: ProcfsBasedProcessTree currently is supported only on Linux.\
17/05/18 01:13:16 INFO mapred.Task:  Using ResourceCalculatorProcessTree : null\
17/05/18 01:13:16 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@23108db7\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10\
17/05/18 01:13:16 INFO reduce.EventFetcher: attempt_local1466891302_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\
17/05/18 01:13:16 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1466891302_0001_m_000000_0 decomp: 6009722 len: 6009726 to MEMORY\
17/05/18 01:13:16 INFO reduce.InMemoryMapOutput: Read 6009722 bytes from map-output for attempt_local1466891302_0001_m_000000_0\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 6009722, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->6009722\
17/05/18 01:13:16 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1466891302_0001_m_000001_0 decomp: 2677274 len: 2677278 to MEMORY\
17/05/18 01:13:16 INFO reduce.InMemoryMapOutput: Read 2677274 bytes from map-output for attempt_local1466891302_0001_m_000001_0\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2677274, inMemoryMapOutputs.size() -> 2, commitMemory -> 6009722, usedMemory ->8686996\
17/05/18 01:13:16 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: 2 / 2 copied.\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\
17/05/18 01:13:16 INFO mapred.Merger: Merging 2 sorted segments\
17/05/18 01:13:16 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 8686956 bytes\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: Merged 2 segments, 8686996 bytes to disk to satisfy reduce memory limit\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: Merging 1 files, 8686998 bytes from disk\
17/05/18 01:13:16 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\
17/05/18 01:13:16 INFO mapred.Merger: Merging 1 sorted segments\
17/05/18 01:13:16 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8686974 bytes\
17/05/18 01:13:16 INFO mapred.LocalJobRunner: 2 / 2 copied.\
17/05/18 01:13:16 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\
17/05/18 01:13:17 INFO mapred.Task: Task:attempt_local1466891302_0001_r_000000_0 is done. And is in the process of committing\
17/05/18 01:13:17 INFO mapred.LocalJobRunner: 2 / 2 copied.\
17/05/18 01:13:17 INFO mapred.Task: Task attempt_local1466891302_0001_r_000000_0 is allowed to commit now\
17/05/18 01:13:17 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1466891302_0001_r_000000_0' to hdfs://localhost:9000/user/davinderkumar/out/_temporary/0/task_local1466891302_0001_r_000000\
17/05/18 01:13:17 INFO mapred.LocalJobRunner: reduce > reduce\
17/05/18 01:13:17 INFO mapred.Task: Task 'attempt_local1466891302_0001_r_000000_0' done.\
17/05/18 01:13:17 INFO mapred.LocalJobRunner: Finishing task: attempt_local1466891302_0001_r_000000_0\
17/05/18 01:13:17 INFO mapred.LocalJobRunner: reduce task executor complete.\
17/05/18 01:13:17 INFO mapreduce.Job:  map 100% reduce 100%\
17/05/18 01:13:17 INFO mapreduce.Job: Job job_local1466891302_0001 completed successfully\
17/05/18 01:13:17 INFO mapreduce.Job: Counters: 35\
	File System Counters\
		FILE: Number of bytes read=17428586\
		FILE: Number of bytes written=33109306\
		FILE: Number of read operations=0\
		FILE: Number of large read operations=0\
		FILE: Number of write operations=0\
		HDFS: Number of bytes read=520115696\
		HDFS: Number of bytes written=2444718\
		HDFS: Number of read operations=22\
		HDFS: Number of large read operations=0\
		HDFS: Number of write operations=5\
	Map-Reduce Framework\
		Map input records=361958\
		Map output records=361958\
		Map output bytes=7963076\
		Map output materialized bytes=8687004\
		Input split bytes=238\
		Combine input records=0\
		Combine output records=0\
		Reduce input groups=196890\
		Reduce shuffle bytes=8687004\
		Reduce input records=361958\
		Reduce output records=111102\
		Spilled Records=723916\
		Shuffled Maps =2\
		Failed Shuffles=0\
		Merged Map outputs=2\
		GC time elapsed (ms)=50\
		Total committed heap usage (bytes)=1199570944\
	Shuffle Errors\
		BAD_ID=0\
		CONNECTION=0\
		IO_ERROR=0\
		WRONG_LENGTH=0\
		WRONG_MAP=0\
		WRONG_REDUCE=0\
	File Input Format Counters \
		Bytes Read=192946936\
	File Output Format Counters \
		Bytes Written=2444718\
\
\
Tempo impiegato HadoopTop5: 6.461}